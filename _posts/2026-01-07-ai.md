---
layout: post
title: "Implementing a Computer Vision model for a real life problem"
date: 2026-01-07
tags: [computer-vision]
---

## Overview
I took NVIDIA's "Computer Vision for Industrial Inspection" course from their Deep Learning Institute to learn more about how computer vision is used in real life. I'd previously taken a lecture on computer vision, but this course expanded more on how to prepare a dataset of images, and create/fine-tune a more advanced computer vision model so that we could detect any desired defects/problems in said dataset.

## The dataset
The point of this exercise was to work on a classification model that could detect any defects in a given dataset. The dataset has many pictures of pcbs, and we want to see which ones have problems. More traditional automated machines usually have a very high false-positive (when we have no errors but the machine flags it as such) rate, which defeats the purpose of automation.

First we want to identify what problem we're solving, then gather a bunch of data on said problem. We curate the data (filter out any unusable/unhelpful data) as well. In the course, the dataset was provided, and used pandas to organize and manage the dataset. To do so, we iterate over our dataset's directory to go over every image and parse its name to obtain the dataframe entries, such as the image's name, resolution (shape), whether or not it has a true defect, etc. 

### Key commands
1. Use a list to keep track of rows
2. convert list to dataframe using pd.DataFrame(list).
3. Also check for duplicates using the df.duplicated() function, use df.sort_values() to sort
4. we can filter for a column using df['column name'].
5. we can use functions like pivot_table(), groupby(), value_counts() to obtain information or manipulate our dataframe.

### Data Preprocessing with DALI
In addition, we can work on pre-processing our dataset using something called DALI (NVIDIA Data Loading Library) for more convenient preprocessing and implementation (similar methods as traning => less repetition).

1. use nvidia.dali to import relevant library.
2. we can use fn.readers.file() to read encoded images and labels from the hard drive
3. decode images by using images = fn.decoders.image() (JPG => RGB format)
4. call build() on a created pipeline (def pipeline()) to use it.
5. we can call functions like fn.rotate() on our images to augment the dataset.

## Creating and Fine-tuning our CV model

## Optimizing model performance